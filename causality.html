<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="author" content="Emma and Thea Gunnarsson">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Emma Gunnarsson</title>
</head>
<body>
    <header>
        <!--#93B8A0 #528765-->
        <a href="index.html"> <img class="HeaderImage2" src="images/initialerskuggad2.png" alt="Logotype"></a>
        <img src="images/emma_gunnarsson_v3.png" class="HeaderImage1" alt="Emma Gunnarsson">
    </header>
    <nav>
        <ul id= "menu">
            <li><a href="case.html">Case Philosophy</a></li>
            <li><a href="projects.html">Projects</a></li>
            <li><a href="Cv.html">CV</a></li>
            <li><a href="work.html">Work Samples</a></li>
        </ul>
    </nav>
    <main>
        <a href="case.html"><img class="growS icons" style="float: left;" height=24px src="icons/back3.png"></a>
        <br>
        <h2>Causality</h2>
        <p>Testing for causal relationships is extremely common in my major field of study; econometrics. Questions could concern a large 
            variety of issues: For example the private or societal gains from education or health investments, effects of immigration, taxes, 
            private investments, or really the effects of any new policy.</p>  
        <p>  Businesses also benefit from tests of causal relationships, for example when designing their web pages, email blasts, or ads. 
            Tests can help in examining user behavior before committing to major changes, which increases the chances of success. These tests 
            are commonly referred to as A/B testing.</p> 
        <p>   A/B testing is a randomized experiment where different segments of customers or users are shown different versions of the webpage, 
            email, or ad. Using various statistical techniques we determine which version works best. A/B testing is done in broadly five steps:</p>  
        <h5>Define treatment</h5>
        <p>What are we interested in testing? Perhaps, we would like to change the color of the Buy now button or change the subject 
            line in our newsletter. Whatever change we would like to test, is the treatment. The old version is then refred to as the 
            control. The versions we compare should not be entirely different from each other, since it will make it impossible to 
            disentangle what is actually being tested. Better then, to stick to smaller, well-defined treatments.</p>
        <h5>Determine the outcome of interest</h5>
        <p>We need to define the outcome of interest. It could be the number of clicks through rates, revenues, number of interactions, 
            or whatever is useful in our particular setting.</p>
        <h5>Define the hypothesis</h5>
        <p>Hypothesis testing in statistics is a method of testing the results of an experiment to see if they are actually meaningful. 
            Using a frequentist approach, one defines a null hypothesis to be tested against an alternate hypothesis. The null could commonly 
            be that the treatment does not have any effect whatsoever, while the alternative states that there is some effect. Using the data 
            sample and some statistical analysis, one can determine whether one should reject the null or not.</p>
        <h5>Design the experiment</h5>
        <p>The golden standard when looking for causal relationships is randomization. Users should randomly be assigned to the control 
            group or the treatment group, where the control group sees the old version and the treatment group sees the new version. 
            The randomization will (hopefully) make sure that the two groups are completely alike in everything except receiving the 
            treatment. Then, any potential differences in the outcome depend only on the treatment and not anything unobserved.</p>
        <p>Importantly, we should avoid contamination between treatment and control groups. For example, each group should only see 
            their one and only version even when updating the interface. Another issue in some settings could be spillover effects, 
            where treated and controls interact and thereby inform each other on the other group. </p>
        <p>Our analysis is really no better than the quality of our sample. If the randomization for some reason failed, or if we only 
            include parts of the population of interest, it is going to be hard to interpret the effects meaningfully. Imagine for example 
            our sample happens to consist only of women; of course, we will not be able to draw any inference about men based on it.</p>
        <p>Another important aspect to consider is power. If our sample is small, it might be difficult to observe differences between 
            treatment and control, especially if the true effect too is small. On the other hand, a too large sample size might pick up 
            on extremely small differences stemming only from the random variation in the data. Besides, a very large sample will take 
            a lot of time to collect and analyze. Therefore, we must choose the sample size consciously.</p>
        <h5>Do the analysis</h5>
        <p>There are many useful statistical techniques to determine whether the obtained results are meaningful or not. If a result 
            is statistically significant, we may conclude there is some effect of the treatment. The next question then, is whether 
            the result is practically significant; in other words, whether the effect is of a high enough magnitude to actually be 
            important.</p>
        <br>
        <a href="case.html"><img class="growS icons" style="float: left;" height=24px src="icons/back3.png"></a>
    </main>
    <footer>
        <a href="https://www.linkedin.com/in/emma-gunnarsson-91b57a131/" target="_blank" rel="noopener noreferrer"> <img class="HeaderImage2 footerDiv" src="icons/linkedin1.png" alt="Logotype"></a>
        <a href="https://public.tableau.com/app/profile/emma1068" target="_blank" rel="noopener noreferrer"> <img class="HeaderImage2 footerDiv" src="icons/tableau1.png" alt="Logotype"></a>
        <a href="https://github.com/EmmaGunnarsson" target="_blank" rel="noopener noreferrer"> <img class="HeaderImage2 footerDiv" src="icons/github5.png" alt="Logotype"></a>
    </footer>
</body>
</html>